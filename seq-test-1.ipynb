{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is running.\n"
     ]
    }
   ],
   "source": [
    "# Libraries import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as func\n",
    "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence\n",
    "\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "# GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is running.\")\n",
    "    dev = \"cuda\"\n",
    "else:\n",
    "    print(\"CPU is running.\")\n",
    "    dev = \"cpu\"\n",
    "\n",
    "device = torch.device(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_938478/2045651676.py:2: DtypeWarning: Columns (13,63,75,93,94,98) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataset_all_rows_total = pd.read_csv('data/data_main.tsv',sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "# Dataset \n",
    "dataset_all_rows_total = pd.read_csv('data/data_main.tsv',sep='\\t')\n",
    "\n",
    "count = 0\n",
    "tfs = []\n",
    "\n",
    "tfs_id = []\n",
    "\n",
    "strength_sequence = []\n",
    "\n",
    "full_sequence = []\n",
    "\n",
    "dataset_all_rows = dataset_all_rows_total.sample(frac=0.02, random_state= 42)\n",
    "\n",
    "# seprating original sequence, motifs, positions\n",
    "\n",
    "for index, sequence in dataset_all_rows.iterrows():\n",
    "\n",
    "    motif_id = []\n",
    "\n",
    "\n",
    "    for col_index in range(1, len(sequence) -3): \n",
    "        \n",
    "        if pd.notna(sequence[col_index]): \n",
    "        \n",
    "            motif_id.append(col_index)  \n",
    "\n",
    "    tfs_id.append(motif_id)\n",
    "\n",
    "    sequence = np.array(sequence.dropna().values)\n",
    "\n",
    "    full_sequence.append(sequence[0])\n",
    "\n",
    "    count+=1\n",
    "\n",
    "    motif_id = []\n",
    "    \n",
    "    tfs.append(sequence[1:-3])\n",
    "\n",
    "    strength_sequence.append(sequence[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Separating the motifs and position\n",
    "all_motifs = []\n",
    "all_positions = []\n",
    "\n",
    "for seq_index, motifs in enumerate(tfs):\n",
    "\n",
    "    motifs_sequence = []\n",
    "    position_motifs = []\n",
    "\n",
    "    for each_item in motifs:\n",
    "\n",
    "        each_motif = each_item.split(':')[0]\n",
    "\n",
    "        each_motif_position = int(each_item.split(':')[1])\n",
    "\n",
    "        motifs_sequence.append(each_motif)\n",
    "\n",
    "        position_motifs.append(each_motif_position)            \n",
    "\n",
    "    all_motifs.append(motifs_sequence)\n",
    "\n",
    "    all_positions.append(position_motifs)\n",
    "\n",
    "\n",
    "# Arranging motifs in order\n",
    "\n",
    "sorted_motifs_list = []\n",
    "\n",
    "sorted_positions = []\n",
    "full_sequence_all = []\n",
    "\n",
    "sorted_class_id = []\n",
    "\n",
    "for index in range(len(all_motifs)):\n",
    "\n",
    "    temp_zip = list(zip(all_motifs[index], all_positions[index], tfs_id[index]))\n",
    "\n",
    "    if not temp_zip:  # Skip empty cases\n",
    "        continue\n",
    "\n",
    "    sorted_zip = sorted(temp_zip, key=lambda x: x[1])\n",
    "\n",
    "    sorted_motifs, sorted_position, sorted_id = zip(*sorted_zip)\n",
    "\n",
    "    sorted_motifs_list.append(sorted_motifs)\n",
    "    sorted_positions.append(sorted_position)\n",
    "\n",
    "    sorted_class_id.append(sorted_id)\n",
    "\n",
    "    full_sequence_all.append(full_sequence[index])\n",
    "\n",
    "\n",
    "# Filtering empty tokens if present\n",
    "strength_sequence_filtered = []\n",
    "\n",
    "\n",
    "def removeEmptyMotifs(motifs_list):\n",
    "\n",
    "    index = 0\n",
    "\n",
    "\n",
    "    filtered_motifs = []\n",
    "\n",
    "    for item in motifs_list:\n",
    "\n",
    "        if len(item) > 0:\n",
    "\n",
    "            filtered_motifs.append(item)\n",
    "\n",
    "            strength_sequence_filtered.append(strength_sequence[index])\n",
    "\n",
    "        index+=1\n",
    "\n",
    "    return filtered_motifs\n",
    "\n",
    "\n",
    "def removeEmpty(motifs_list):\n",
    "\n",
    "    filtered_motifs = []\n",
    "\n",
    "    for item in motifs_list:\n",
    "\n",
    "\n",
    "        if len(item) > 0:\n",
    "\n",
    "            filtered_motifs.append(item)\n",
    "\n",
    "    return filtered_motifs\n",
    "\n",
    "filtered_tokens = removeEmptyMotifs(sorted_motifs_list)\n",
    "\n",
    "position_sequences = removeEmpty(sorted_positions)\n",
    "\n",
    "strength_sequence = strength_sequence_filtered "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding sequences using one-hot encoding\n",
    "encoding = {\n",
    "    'A': [0, 0],\n",
    "    'C': [0, 1],\n",
    "    'G': [1, 0],\n",
    "    'T': [1, 1]\n",
    "}\n",
    "\n",
    "def one_hot_encoding(motifs_sequences):\n",
    "\n",
    "    all_motifs_encoded = []\n",
    "\n",
    "    for seq in motifs_sequences:\n",
    "\n",
    "        encoded = []\n",
    "\n",
    "        for each_motif in seq:\n",
    "\n",
    "            encoded_seq = []\n",
    "\n",
    "            for base in each_motif:\n",
    "\n",
    "                if base in encoding:\n",
    "\n",
    "                    encoded_seq.extend(encoding[base])\n",
    "\n",
    "            encoded.append(''.join(map(str, encoded_seq)))\n",
    "\n",
    "        all_motifs_encoded.append(encoded)\n",
    "\n",
    "    return all_motifs_encoded\n",
    "\n",
    "\n",
    "encoded_motifs_list = one_hot_encoding(filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating embedding of the encoded information\n",
    "\n",
    "encoded_motifs_list_all = []\n",
    "\n",
    "for seq in encoded_motifs_list:\n",
    "\n",
    "    motifs_list = []\n",
    "\n",
    "    for motif in seq:\n",
    "\n",
    "\n",
    "        \n",
    "        motif_tensor = torch.tensor([int(bit) for bit in motif], dtype=torch.float32)\n",
    "\n",
    "\n",
    "        input_dim = len(motif)\n",
    "\n",
    "        linear = nn.Linear(input_dim, 50)\n",
    "\n",
    "\n",
    "        motif_tensor = motif_tensor.view(1, -1)\n",
    "\n",
    "        output = linear(motif_tensor)\n",
    "\n",
    "        output = output.reshape(-1,)\n",
    "\n",
    "        motifs_list.append(output.detach())\n",
    "\n",
    "    encoded_motifs_list_all.append(motifs_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filtering sequence = []\n",
    "\n",
    "def filterSequenceByPosition(encoded_motifs_list, all_positions, original_motif_sequences):\n",
    "    sorted_vector_representations = []\n",
    "    sorted_positions = []\n",
    "    sorted_original_words = []\n",
    "    sorted_class_ids = []\n",
    "\n",
    "    for index in range(len(encoded_motifs_list)):\n",
    "\n",
    "        temp_zip = list(zip(encoded_motifs_list[index],all_positions[index], original_motif_sequences[index]))\n",
    "\n",
    "        sorted_zip = sorted(temp_zip,key=lambda x: x[1])\n",
    "\n",
    "        sorted_vec,sorted_position,sorted_word = zip(*sorted_zip)\n",
    "\n",
    "        sorted_vector_representations.append(sorted_vec)\n",
    "        sorted_positions.append(sorted_position)\n",
    "        sorted_original_words.append(sorted_word)\n",
    "        # sorted_class_ids.append(class_ids)\n",
    "\n",
    "    return sorted_vector_representations,sorted_positions,sorted_original_words\n",
    "\n",
    "sorted_motif_encoding_representations , sorted_motif_positions, sorted_original_motifs = filterSequenceByPosition(encoded_motifs_list_all, position_sequences, filtered_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[90], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m train_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(all_indices, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_indices)))\n\u001b[1;32m      5\u001b[0m test_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(all_indices)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mset\u001b[39m(train_indices)))\n\u001b[0;32m----> 7\u001b[0m training_vec_sequences \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      8\u001b[0m     torch\u001b[38;5;241m.\u001b[39mstack([sub_seq\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m sub_seq \u001b[38;5;129;01min\u001b[39;00m sorted_motif_encoding_representations[index]])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     12\u001b[0m training_sequences_positions \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(sorted_motif_positions[index]))\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices]\n\u001b[1;32m     13\u001b[0m training_motifs_sequences \u001b[38;5;241m=\u001b[39m [sorted_original_motifs[index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices]\n",
      "Cell \u001b[0;32mIn[90], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m train_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(all_indices, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_indices)))\n\u001b[1;32m      5\u001b[0m test_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(all_indices)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mset\u001b[39m(train_indices)))\n\u001b[1;32m      7\u001b[0m training_vec_sequences \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 8\u001b[0m     torch\u001b[38;5;241m.\u001b[39mstack([sub_seq\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m sub_seq \u001b[38;5;129;01min\u001b[39;00m sorted_motif_encoding_representations[index]])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     12\u001b[0m training_sequences_positions \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(sorted_motif_positions[index]))\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices]\n\u001b[1;32m     13\u001b[0m training_motifs_sequences \u001b[38;5;241m=\u001b[39m [sorted_original_motifs[index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices]\n",
      "Cell \u001b[0;32mIn[90], line 8\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m train_indices \u001b[38;5;241m=\u001b[39m random\u001b[38;5;241m.\u001b[39msample(all_indices, \u001b[38;5;28mint\u001b[39m(\u001b[38;5;241m0.8\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_indices)))\n\u001b[1;32m      5\u001b[0m test_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(all_indices)\u001b[38;5;241m.\u001b[39mdifference(\u001b[38;5;28mset\u001b[39m(train_indices)))\n\u001b[1;32m      7\u001b[0m training_vec_sequences \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 8\u001b[0m     torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43msub_seq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sub_seq \u001b[38;5;129;01min\u001b[39;00m sorted_motif_encoding_representations[index]])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices\n\u001b[1;32m     10\u001b[0m ]\n\u001b[1;32m     12\u001b[0m training_sequences_positions \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mfrom_numpy(np\u001b[38;5;241m.\u001b[39marray(sorted_motif_positions[index]))\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices]\n\u001b[1;32m     13\u001b[0m training_motifs_sequences \u001b[38;5;241m=\u001b[39m [sorted_original_motifs[index] \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m train_indices]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Making training and testing seqeunces\n",
    "\n",
    "all_indices = [val for val in range(len(sorted_motif_encoding_representations))]\n",
    "train_indices = random.sample(all_indices, int(0.8 * len(all_indices)))\n",
    "test_indices = list(set(all_indices).difference(set(train_indices)))\n",
    "\n",
    "training_vec_sequences = [\n",
    "    torch.stack([sub_seq.to(dtype=torch.float32, device=device) for sub_seq in sorted_motif_encoding_representations[index]])\n",
    "    for index in train_indices\n",
    "]\n",
    "\n",
    "training_sequences_positions = [torch.from_numpy(np.array(sorted_motif_positions[index])).to(dtype=torch.long, device=device) for index in train_indices]\n",
    "training_motifs_sequences = [sorted_original_motifs[index] for index in train_indices]\n",
    "training_sequence_strength= [torch.from_numpy(np.array(strength_sequence[index])).to(dtype=torch.float32, device=device) for index in train_indices]\n",
    "\n",
    "testing_vec_sequences = [\n",
    "    torch.stack([sub_seq.to(dtype=torch.float32, device=device) for sub_seq in sorted_motif_encoding_representations[index]])\n",
    "    for index in test_indices\n",
    "]\n",
    "\n",
    "testing_sequences_positions = [torch.from_numpy(np.array(sorted_motif_positions[index])).to(dtype=torch.long, device=device) for index in test_indices]\n",
    "testing_motifs_sequences = [sorted_original_motifs[index] for index in test_indices]\n",
    "testing_sequence_strength = [torch.from_numpy(np.array(strength_sequence[index])).to(dtype=torch.float32, device=device) for index in test_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data batches\n",
    "\n",
    "# Get data batches\n",
    "def getBatches(vec_data, original_data, positions, outputs,batch_size = 1):\n",
    "    counter = 0\n",
    "\n",
    "    vec_data_batches = []\n",
    "    original_data_batches = []\n",
    "    position_data_batches = []\n",
    "    output_data_batches = []\n",
    "\n",
    "    while counter < len(vec_data):\n",
    "        batched_vec_data = vec_data[counter: counter+batch_size][0]\n",
    "        batched_original_data = original_data[counter:counter+batch_size][0]\n",
    "        batched_position_data = positions[counter:counter+batch_size][0]\n",
    "        batched_output_data = outputs[counter: counter+batch_size][0]\n",
    "\n",
    "        counter = counter + batch_size\n",
    "\n",
    "        vec_data_batches.append(batched_vec_data)\n",
    "        original_data_batches.append(batched_original_data)\n",
    "        position_data_batches.append(batched_position_data)\n",
    "        output_data_batches.append(batched_output_data)\n",
    "\n",
    "    return (vec_data_batches, original_data_batches, position_data_batches, output_data_batches)\n",
    "\n",
    "# Training batches\n",
    "\n",
    "seq_training_batches, training_motifs_batches, trainining_motifs_positions_batches, training_strength_batches = getBatches(training_vec_sequences, training_motifs_sequences, training_sequences_positions, training_sequence_strength)\n",
    "\n",
    "# Testing batches\n",
    "\n",
    "seq_testing_batches, testing_motifs_batches, testing_motifs_positions_batches, testing_strength_batches = getBatches(testing_vec_sequences, testing_motifs_sequences, testing_sequences_positions, testing_sequence_strength)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positional embedding\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000, negative_dist = 250, positive_dist = 50):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        self.negative_dist = negative_dist\n",
    "        self.d_model = d_model\n",
    "\n",
    "        self.seq_length = negative_dist + positive_dist\n",
    "\n",
    "        position = torch.arange(0,self.seq_length,device = device).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)).to(device=device)\n",
    "\n",
    "        pe = torch.zeros(self.seq_length, 1, d_model).to(device=device)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term).to(device=device)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term).to(device=device)\n",
    "\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x, positions):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        batch_size, seq_len , embedding_dim = x.shape\n",
    "\n",
    "        x = x.transpose(1,0)\n",
    "\n",
    "        indices = positions.reshape(-1) + self.negative_dist\n",
    "\n",
    "        x = x + self.pe[indices]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x.transpose(1,0)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch Number: 1 Loss : 68424.30831447463\n",
      "Epoch Number: 2 Loss : 68171.03461568187\n",
      "Epoch Number: 3 Loss : 68059.3068385293\n",
      "Epoch Number: 4 Loss : 67992.92851136725\n",
      "Time Elapsed: 68.97268748283386\n",
      "Training Epoch Losses: [68424.30831447463, 68171.03461568187, 68059.3068385293, 67992.92851136725]\n"
     ]
    }
   ],
   "source": [
    "class GeneFormer(nn.Module):\n",
    "    def __init__(self, input_dim = 50, model_dim = 512, n_output_heads = 1, nhead = 4, enc_layers_count = 3, motif_count = 1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.model_dim = model_dim\n",
    "\n",
    "        self.motif_count = motif_count\n",
    "\n",
    "        self.n_output_heads = n_output_heads\n",
    "\n",
    "        self.nhead = nhead\n",
    "        self.enc_layers_count = enc_layers_count\n",
    "\n",
    "        # Linear Layers for the input.\n",
    "\n",
    "        self.input_embedding_1 = torch.nn.Linear(self.input_dim, int((self.model_dim)/2))\n",
    "        self.input_embedding_2 = torch.nn.Linear(int((self.model_dim)/2), self.model_dim)\n",
    "\n",
    "        self.positional_embedding = PositionalEncoding(d_model=self.model_dim)\n",
    "\n",
    "        # Transformer model definition.\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=self.model_dim, nhead=self.nhead)\n",
    "        self.encoders = torch.nn.TransformerEncoder(self.encoder_layer , num_layers = self.enc_layers_count)\n",
    "\n",
    "        # Final output layer for the model.\n",
    "\n",
    "        self.genetics_classifier_1 = torch.nn.Linear(self.model_dim, int((self.model_dim /2)))\n",
    "\n",
    "        self.genetics_classifier_2 = torch.nn.Linear(int((self.model_dim /2)), self.n_output_heads)\n",
    "\n",
    "        self.activation_relu = torch.nn.ReLU()\n",
    "\n",
    "        # Dropout Functions\n",
    "        self.dropout_5 = torch.nn.Dropout(p = 0.05)\n",
    "        self.dropout_10 = torch.nn.Dropout(p = 0.10)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,inputs, positions):\n",
    "\n",
    "        batch_size, seq_length, features = inputs.shape\n",
    "\n",
    "        embedded_input = self.input_embedding_1(inputs)\n",
    "\n",
    "        embedded_input = self.dropout_5(embedded_input)\n",
    "\n",
    "        embedded_input = self.input_embedding_2(embedded_input)\n",
    "\n",
    "        embedded_input = self.dropout_5(embedded_input)\n",
    "\n",
    "        embedded_input = embedded_input.reshape(batch_size,seq_length,self.model_dim)\n",
    "\n",
    "        positional_embedded_input = self.positional_embedding(embedded_input, positions)\n",
    "\n",
    "        encoded_x = self.encoders(positional_embedded_input)\n",
    "\n",
    "        encoded_x = torch.mean(encoded_x, dim = 1)\n",
    "\n",
    "        encoded_x = torch.mean(encoded_x, dim = 0)\n",
    "\n",
    "        output_x = self.genetics_classifier_1(encoded_x)\n",
    "\n",
    "        output_x = self.activation_relu(output_x)\n",
    "\n",
    "        output_x = self.genetics_classifier_2(output_x)\n",
    "\n",
    "        return output_x.reshape(-1,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration\n",
    "\n",
    "gene_model = GeneFormer(input_dim = 50, model_dim = 512, n_output_heads= 1, nhead= 4 , enc_layers_count= 4, motif_count = 1)\n",
    "\n",
    "gene_model = gene_model.to(device=device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(gene_model.parameters(), lr= 5e-5)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3 ,gamma = 0.6, last_epoch= -1, verbose=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "\n",
    "def TrainModel(seq_representation_inputs, motifs_inputs, position_inputs, strength_output, epoch_number):\n",
    "\n",
    "    total_loss = 0\n",
    "    total_batches = 0\n",
    "    batch_size = 1\n",
    "\n",
    "    for seq_index , batch_input in enumerate(seq_representation_inputs):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_batches +=1\n",
    "\n",
    "        position_input = position_inputs[seq_index].reshape(1,-1,1).to(device)\n",
    "        actual_output = strength_output[seq_index].reshape(-1).to(device)\n",
    "        tokens, features = batch_input.shape\n",
    "        batch_input = batch_input.reshape(batch_size,tokens,features)\n",
    "\n",
    "        output = gene_model(batch_input, position_input)\n",
    "        loss = criterion(output,actual_output).to(device)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss+=loss.item()\n",
    "    print('Epoch Number: {} Loss : {}'.format(epoch_number, total_loss / (total_batches)))\n",
    "    return total_loss / (total_batches)\n",
    "\n",
    "# Training parameters\n",
    "\n",
    "epoch_number = 1\n",
    "epoch_end_count = 0\n",
    "train_epoch_avg_losses_sp = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "gene_model.train(True)\n",
    "\n",
    "\n",
    "\n",
    "while epoch_number <= 4:\n",
    "\n",
    "    temp_holder = list(zip(seq_training_batches, training_motifs_batches, trainining_motifs_positions_batches, training_strength_batches))\n",
    "    random.shuffle(temp_holder)\n",
    "    seq_training_batches, training_motifs_batches, trainining_motifs_positions_batches, training_strength_batches = zip(*temp_holder)\n",
    "\n",
    "    epoch_loss_sp, weight_change_classfier, weight_chage_encoder = TrainModel(seq_training_batches, training_motifs_batches, trainining_motifs_positions_batches, training_strength_batches, epoch_number)\n",
    "\n",
    "    epoch_number += 1\n",
    "    if epoch_number % 2 == 0:\n",
    "\n",
    "        checkpoint = {\n",
    "        'epoch': epoch_number,  \n",
    "        'model_state_dict': gene_model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        }\n",
    "        torch.save(checkpoint, '/local/data/sdahal_p/genome-test/model_checkpoint_terminal.pth')\n",
    "\n",
    "    train_epoch_avg_losses_sp.append(epoch_loss_sp)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Time Elapsed:\", end_time - start_time)\n",
    "print(\"Training Epoch Losses:\", train_epoch_avg_losses_sp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing starts\n",
    "\n",
    "gene_model.eval()\n",
    "\n",
    "def TestGeneModel(seq_representation_inputs, motifs_inputs, position_inputs, strength_output):\n",
    "\n",
    "    actual_strength_values = []\n",
    "\n",
    "    predicted_strength_values = []\n",
    "\n",
    "    total_batches = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for input_index , batch_input in enumerate(seq_representation_inputs):\n",
    "\n",
    "            total_batches +=1\n",
    "\n",
    "            batch_size = 1\n",
    "\n",
    "            position_input = position_inputs[input_index].reshape(1,-1,1)\n",
    "\n",
    "            actual_output = strength_output[input_index].reshape(-1)\n",
    "\n",
    "            tokens, features = batch_input.shape\n",
    "\n",
    "            batch_input = batch_input.reshape(batch_size,tokens,features)\n",
    "\n",
    "            output = gene_model(batch_input, position_input).to(device)\n",
    "\n",
    "            actual_strength_values.append(actual_output)\n",
    "\n",
    "            predicted_strength_values.append(output)\n",
    "\n",
    "    return actual_strength_values, predicted_strength_values\n",
    "\n",
    "\n",
    "actual_values, predicted_values = TestGeneModel(seq_testing_batches, testing_motifs_batches, testing_motifs_positions_batches, testing_strength_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([239.], device='cuda:0')\n",
      "tensor([1.0020], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Saving test results in csv file\n",
    "\n",
    "import csv\n",
    "\n",
    "print((actual_values[1]))\n",
    "print(predicted_values[1])\n",
    "\n",
    "\n",
    "import torch\n",
    "actual_values = torch.tensor(actual_values, device='cuda:1')\n",
    "predicted_values = torch.tensor(predicted_values, device='cuda:1')\n",
    "\n",
    "\n",
    "actual_values = actual_values.cpu().numpy() \n",
    "predicted_values = predicted_values.cpu().numpy()\n",
    "\n",
    "data = {\n",
    "    \"Actual Values\": actual_values,\n",
    "    \"Predicted Values\": predicted_values\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "file_name = \"/local/data/sdahal_p/genome-test/result/strength_values.csv\"\n",
    "\n",
    "df.to_csv(file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading for testing\n",
    "\n",
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "gene_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
